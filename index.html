<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-132787383-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-132787383-1');
</script>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Tianlu's homepage</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/full-width-pics.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body style="font-family:Gill Sans">

    <!-- Full Width Image Header with Logo -->
    <!-- Image backgrounds are set within the full-width-pics.css file. -->
<!--     <header class="image-bg-fluid-height">
        <img class="img-responsive img-center" src="./assets/img/avator.jpg" alt="">
    </header> -->

    <!-- Content Section -->
    <div class="container">
        <div class="page-header" style="margin-top: -10px;">
            <div class="row" style="padding-bottom: 5px;">
                <h1 style="font-family:Optima;font-size:200%">
                  <span>Tianlu Wang</span>
                </h1>
            </div>
        </div>

        <div class="row">
<!--             <div class="col-xs-12 col-md-3">
                <h3 style="margin-top: auto;">Contact me</h3>
                <ul style="font-family:Gill Sans;font-size:130%">
                    <li>E-mail: tianlu[at]virginia[dot]edu</li>
                    <li>Address: 430 Rice Hall, Charlottesville, VA.</li>
                    <li><a href="./assets/pdf/cv.pdf">[curriculum vitae]</a></li>
                </ul>
            </div> -->
            
            <div class="col-xs-12 col-md-3" style="text-align: left; vertical-align: middle;">
                <img src="./assets/img/avator.jpeg" width="220px"/>
                <br>
                <a href="https://www.linkedin.com/in/tianluwang" target="_blank" style="display: inline-block; margin-top: 10px;">
                <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="#0A66C2" viewBox="0 0 24 24" style="vertical-align: middle;">
                <path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.761 0 5-2.239 5-5v-14c0-2.761-2.239-5-5-5zm-11 19h-3v-10h3v10zm-1.5-11.268c-.966 0-1.75-.784-1.75-1.75s.784-1.75 1.75-1.75 1.75.784 1.75 1.75-.784 1.75-1.75 1.75zm13.5 11.268h-3v-5.604c0-1.337-.025-3.063-1.868-3.063-1.868 0-2.154 1.459-2.154 2.967v5.7h-3v-10h2.881v1.367h.041c.401-.761 1.381-1.563 2.841-1.563 3.039 0 3.6 2.001 3.6 4.601v5.595z"/>
                </svg>
                <span class="sr-only">LinkedIn</span>
                </a>
              <a href="https://scholar.google.com/citations?user=inzQqX8AAAAJ" target="_blank" style="display: inline-block; margin-top: 10px; margin-left: 10px;">
              <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 48 48" style="vertical-align: middle;">
              <g>
              <circle cx="24" cy="24" r="24" fill="#fff"/>
              <path d="M24 12c-6.627 0-12 5.373-12 12s5.373 12 12 12c5.302 0 9.8-3.438 11.385-8.205h-8.385v-3.59h13.205c.09-.564.145-1.14.145-1.705 0-1.13-.102-2.22-.29-3.265h-13.06v-3.59h12.385c-2.09-4.97-7.01-8.205-12.385-8.205z" fill="#4285F4"/>
              <path d="M12 24c0-1.13.102-2.22.29-3.265l7.715 5.955v3.59l-7.715 5.955c-1.188-2.045-1.89-4.41-1.89-6.955z" fill="#34A853"/>
              <path d="M24 36c-3.24 0-6.18-1.08-8.485-2.91l7.715-5.955h3.59l7.715 5.955c-2.305 1.83-5.245 2.91-8.485 2.91z" fill="#FBBC05"/>
              <path d="M36 24c0-1.13-.102-2.22-.29-3.265l-7.715 5.955v3.59l7.715 5.955c1.188-2.045 1.89-4.41 1.89-6.955z" fill="#EA4335"/>
              </g>
              </svg>
              <span class="sr-only">Google Scholar</span>
              </a>
<!--                 <a href="https://scholar.google.com/citations?user=YOUR-SCHOLAR-ID" target="_blank" style="display: inline-block; margin-top: 10px; margin-left: 10px;">
                <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 48 48" fill="#4285F4" style="vertical-align: middle;">
                <path d="M24 4L4 20h6v16h8V28h8v8h8V20h6L24 4z"/>
                <circle cx="24" cy="44" r="4" fill="#34A853"/>
                </svg>
                <span class="sr-only">Google Scholar</span>
                </a> -->
            </div>
      
            <div class="col-xs-12 col-md-7" style="text-align: left; vertical-align: middle;font-family:Gill Sans;font-size:120% ">
                <p class="section-paragraph">I am currently a research scientist at Meta AI, FAIR team, working on large language model post-training. I did my Ph.D. in Computer Science at the <a href="https://www.virginia.edu/">University of Virginia</a>, where I was advised by Prof. <a href="https://www.vicenteordonez.com/">Vicente Ordóñez Román</a>. Before that, I received my bachelor's degree in Computer Science from <a href="http://www.zju.edu.cn/english/">Zhejiang University</a>, China. 
                </p>

            </div>
            
        </div>
        
        <h3>Recent Selected Publications</h3>

<!--       <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/abs/2205.01068">OPT: Open Pre-trained Transformer Language Models</a><br />
                <u>Tianlu Wang</u>, </br>
            </p>
          </div>
        </div> -->
    <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/pdf/2507.00417">ASTRO: Teaching Language Models to Reason by Reflecting and Backtracking In-Context</a><br />
                Joongwon Kim, Anirudh Goyal, Liang Tan, Hannaneh Hajishirzi, Srinivasan Iyer, <u>Tianlu Wang</u>. </br>
            </p>
          </div>
        </div>

      <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/pdf/2505.10320">J1: Incentivizing thinking in llm-as-a-judge via reinforcement learning</a><br />
                Chenxi Whitehouse, <u>Tianlu Wang</u>, Ping Yu, Xian Li, Jason Weston, Ilia Kulikov, Swarnadeep Saha.  </br>
            </p>
          </div>
        </div>

      <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/abs/2504.00927">Multi-Token Attention</a><br />
                Olga Golovneva, <u>Tianlu Wang</u>, Jason Weston, Sainbayar Sukhbaatar. COLM 2025</br>
            </p>
          </div>
        </div>

      <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/pdf/2501.18099?">Learning to plan & reason for evaluation with thinking-llm-as-a-judge</a><br />
                Swarnadeep Saha, Xian Li, Marjan Ghazvininejad, Jason Weston, <u>Tianlu Wang</u>. ICML 2025</br>
            </p>
          </div>
        </div>

      <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/pdf/2408.02666?">Self-taught evaluators</a><br />
                <u>Tianlu Wang</u>,Tianlu Wang, Ilia Kulikov, Olga Golovneva, Ping Yu, Weizhe Yuan, Jane Dwivedi-Yu, Richard Yuanzhe Pang, Maryam Fazel-Zarandi, Jason Weston, Xian Li. </br>
            </p>
          </div>
      
      </div>
          <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/pdf/2405.18719?">Contextual Position Encoding: Learning to Count What's Important</a><br />
                Olga Golovneva, <u>Tianlu Wang</u>, Jason Weston, Sainbayar Sukhbaatar. </br>
            </p>
          </div>
        </div>

      <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/abs/2405.09818">Chameleon: Mixed-modal early-fusion foundation models</a><br />
                Chameleon Team. </br>
            </p>
          </div>
        </div>

      <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/pdf/2308.04592">Shepherd: A critic for language model generation</a><br />
                <u>Tianlu Wang</u>, Ping Yu, Xiaoqing Ellen Tan, Sean O'Brien, Ramakanth Pasunuru, Jane Dwivedi-Yu, Olga Golovneva, Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz. </br>
            </p>
          </div>
        </div>
      
      <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/pdf/2401.17464">Efficient tool use with chain-of-abstraction reasoning</a><br />
               Silin Gao, Jane Dwivedi-Yu, Ping Yu, Xiaoqing Ellen Tan, Ramakanth Pasunuru, Olga Golovneva, Koustuv Sinha, Asli Celikyilmaz, Antoine Bosselut, <u>Tianlu Wang</u>. COLING 2025</br>
            </p>
          </div>
        </div>

      <div class="media" style="font-family:Gill Sans;font-size:110%">
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/pdf/2306.15091">Understanding in-context learning via supportive pretraining data</a><br />
                Xiaochuang Han, Daniel Simig, Todor Mihaylov, Yulia Tsvetkov, Asli Celikyilmaz, <u>Tianlu Wang</u>. ACL 2023</br>
            </p>
          </div>
        </div>
      
      
      <div class="media" style="font-family:Gill Sans;font-size:110%">
<!--           <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/opt.png" width="120px" height="96px"/>
          </a> -->
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/abs/2205.01068">OPT: Open Pre-trained Transformer Language Models</a><br />
                Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster, Daniel Simig, Punit Singh Koura, Anjali Sridhar, <u>Tianlu Wang</u>, Luke Zettlemoyer</br>
<!--                 [<a href="https://arxiv.org/abs/2205.01068">arxiv</a>] -->
<!--                 [<a href="./files/opt.txt">bibtex</a>] -->
            </p>
          </div>
        </div>
  
    <div class="media" style="font-family:Gill Sans;font-size:110%">
<!--           <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/multilingual.png" width="120px" height="96px"/>
          </a> -->
          <div class="media-body">
            <p class="media-heading">
            <a href="https://arxiv.org/abs/2112.10668">Few-shot Learning with Multilingual Language Models</a><br />
                Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, <u>Tianlu Wang</u>, Shuohui Chen, Daniel Simig, Myle Ott, Naman Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettlemoyer, Zornitsa Kozareva, Mona Diab, Veselin Stoyanov, Xian Li. EMNLP 2022</br>
<!--                 [<a href="https://arxiv.org/abs/2112.10668">arxiv</a>] -->
<!--                 [<a href="./files/multilingual.txt">bibtex</a>] -->
            </p>
          </div>
        </div>

      
        <h3>Old Publications</h3>

        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/robust_2022_naacl.png" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
          Identifying and mitigating spurious correlations for improving robustness in NLP models<br />
                <u>Tianlu Wang</u>, Rohit Sridhar, Diyi Yang, Xuezhi Wang</br>
                <span class="pub_info">North American Chapter of the Association for Computational
Linguistics. <u>NAACL 2022 Findings</u>. Seattle, Washington + Online. July. 2022</span><br/> 
                [<a href="https://arxiv.org/abs/2110.07736">arxiv</a>]
                [<a href="https://github.com/tianlu-wang/Identifying-and-Mitigating-Spurious-Correlations-for-Improving-Robustness-in-NLP-Models">code</a>]
                [<a href="./files/naacl_2022.txt">bibtex</a>]
            </p>
          </div>
        </div>

        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/visualnews.png" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
            VisualNews : Benchmark and Challenges in Entity-aware Image Captioning<br />
                Fuxiao Liu, Yinghan Wang, <u>Tianlu Wang</u>, Vicente Ordonez</br>
                <span class="pub_info">Empirical Methods in Natural Language Processing. <u>EMNLP 2021</u>. Punta Cana, Dominican Republic. Nov. 2021</span><br/> 
                [<a href="https://arxiv.org/abs/2010.03743">arxiv</a>]
                [<a href="https://github.com/tianlu-wang/Identifying-and-Mitigating-Spurious-Correlations-for-Improving-Robustness-in-NLP-Models">code</a>]
                [<a href="./files/naacl2021.txt">bibtex</a>]
            </p>
          </div>
        </div>
        
        
        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/multi-label.png" width="120px" height="70px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
            General Multi-label Image Classification with Transformers<br />
            Jack Lanchantin, <u>Tianlu Wang</u>, Vicente Ordonez, Yanjun Qi.</br>
            <span class="pub_info">Intl. Conference on Computer Vision and Pattern Recognition. <u>CVPR 2021</u>. Nashville, TN. June 2021.</span><br/> 
                [<a href="https://arxiv.org/abs/2011.14027">arxiv</a>]
                [<a href="./files/multi-label.txt">bibtex</a>]
            </p>
          </div>
        </div>

        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/cat-gen.png" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
            CAT-Gen: Improving Robustness in NLP Models via Controlled Adversarial Text Generation<br />
                <u>Tianlu Wang</u>, Xuezhi Wang, Yao Qin, Ben Packer, Kang Lee, Jilin Chen, Alex Beutel, Ed Chi</br>
                <span class="pub_info">Empirical Methods in Natural Language Processing. <u>EMNLP 2020</u>. short. Virtual Conference. Nov. 2020</span><br/> 
                [<a href="https://arxiv.org/abs/2010.02338/">arxiv</a>]
                [<a href="./files/cat-gen.txt">bibtex</a>]
            </p>
          </div>
        </div>

        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/double-hard.png" width="120px" height="75px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
            Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation<br />
                <u>Tianlu Wang</u>, Xi Victoria Lin, Nazneen Fatema Rajani, Bryan McCann, Vicente Ordonez, Caiming Xiong</br>
                <span class="pub_info">Association for Computational Linguistics. <u>ACL 2020</u>. Virtual Conference. July 2020.</span><br/> 
                [<a href="https://arxiv.org/abs/2005.00965" />arxiv</a>][<a href="https://github.com/uvavision/Double-Hard-Debias">code</a>][<a href="./files/doublehard.txt">bibtex</a>][<a href="http://www.cs.virginia.edu/~tw8cb/word_embeddings/"/>debiased embeddings</a>]
            </p>
          </div>
        </div>

        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/adv_debias.png" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
            Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations<br />
                <u>Tianlu Wang</u>, Jieyu Zhao, Mark Yatskar, Kai-Wei Chang, Vicente Ordonez.</br>
                <span class="pub_info">International Conference on Computer Vision. <u>ICCV 2019</u>. Seoul, South Korea. October 2019.</span><br/> 
                [<a href="https://arxiv.org/abs/1811.08489" />arxiv</a>][<a href="https://github.com/uvavision/Balanced-Datasets-Are-Not-Enough">code</a>][<a href="./files/gendervision.txt">bibtex</a>]
            </p>
          </div>
        </div>

        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/bias-nlp2019.png" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
              Gender Bias in Contextualized Word Embeddings<br />
                <span class="pub_authors">Jieyu Zhao, <u>Tianlu Wang</u>, Mark Yatskar, Ryan Cotterell, Vicente Ordonez, Kai-Wei Chang.</span><br/>

                <span class="pub_info">North American Chapter of the Association for Computational Linguistics. <u>NAACL 2019</u>. short. <br/>Minneapolis, Minnesota. June 2019.</span><br/>

                [<a href="https://arxiv.org/abs/1904.03310" />arXiv</a>][<a href="./files/genderbiaselmo_bib.txt">bibtex</a>]
            </p>
          </div>
        </div>

        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/feedbackprop.png" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
              Feedback-prop: Convolutional Neural Network Inference under Partial Evidence<br />
              <u>Tianlu Wang</u>, Kota Yamaguchi, Vicente Ordonez<br/><span class="pub_info">Intl. Conference on Computer Vision and Pattern Recognition. <u>CVPR 2018</u>. Salt Lake City, Utah. June 2018.</span><br/>
                [<a href="https://arxiv.org/abs/1710.08049" />arXiv</a>][<a href="https://github.com/uvavision/feedbackprop">code</a>] [<a href="./files/feedbackprop_bib.txt">bibtex</a>]
              <!-- <a href="http://nlp.cs.rpi.edu/paper/expectation2016.pdf">[Link]</a> -->
              <!-- <a href="http://decaf.berkeleyvision.org/">[Live Demo]</a> -->
              <!-- <a href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a> -->
              <!-- <a href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a> -->
            </p>
          </div>
        </div>
        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/bias-nlp2018.png" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
              Gender Bias in Coreference Resolution: Evaluation and Debiasing Methods<br />
                Jieyu Zhao, <u>Tianlu Wang</u>, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang.<br/><span class="pub_info">North American Chapter of the Association for Computational Linguistics. <u>NAACL 2018</u>. short. <br/>New Orleans, Louisiana. June 2018.</span><br/>
                [<a href="https://arxiv.org/abs/1804.06876" />arXiv</a>] [<a href="https://github.com/uclanlp/corefBias">code</a>] [<a href="./files/coref_bias.txt">bibtex</a>] 
              <!-- <a href="http://nlp.cs.rpi.edu/paper/expectation2016.pdf">[Link]</a> -->
              <!-- <a href="http://decaf.berkeleyvision.org/">[Live Demo]</a> -->
              <!-- <a href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a> -->
              <!-- <a href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a> -->
            </p>
          </div>
        </div>
        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/emnlp2017.png" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
              Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints <br />
                Jieyu Zhao, <u>Tianlu Wang</u>, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang.</br>
                Empirical Methods in Natural Language Processing. <u>EMNLP 2017</u>. Copenhagen, Denmark. September 2017.</br>
                [<a href="https://arxiv.org/abs/1707.09457" />arxiv</a>] [<a href="https://github.com/uclanlp/reducingbias">code</a>] [<a href="./files/emnlp2017.txt">bibtex</a>]<em style="color:#a00">(Best Long Paper Award!)</strong></em>
              <!-- <a href="http://nlp.cs.rpi.edu/paper/expectation2016.pdf">[Link]</a> -->
              <!-- <a href="http://decaf.berkeleyvision.org/">[Live Demo]</a> -->
              <!-- <a href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a> -->
              <!-- <a href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a> -->
            </p>
          </div>
        </div>
        <div class="media" style="font-family:Gill Sans;font-size:110%">
          <a class="pull-left" href="#">
            <img class="media-object" src="./assets/img/naacl2016.PNG" width="120px" height="96px"/>
          </a>
          <div class="media-body">
            <p class="media-heading">
              Name Tagging for Low-resource Incident Languages based on Expectation-driven Learning<br />
                Boliang Zhang, Xiaoman Pan, <u>Tianlu Wang</u>, Ashish Vaswani, Heng Ji, Kevin Knight and Daniel Marcu</br>
                North American Chapter of the Association for Computational Linguistics. <u>NAACL 2016</u></br>
              <a href="http://nlp.cs.rpi.edu/paper/expectation2016.pdf">[pdf]</a>
              <!-- <a href="http://decaf.berkeleyvision.org/">[Live Demo]</a> -->
              <!-- <a href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a> -->
              <!-- <a href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a> -->
            </p>
          </div>
        </div>

    </div>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-12">
                    <!-- <p>Copyright &copy; Tianlu Wang 2016</p> -->
                </div>
            </div>
            <!-- /.row -->
        </div>
        <!-- /.container -->
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</body>

</html>
